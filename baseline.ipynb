{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WONJONGHYEON\\anaconda3\\envs\\CP2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS':10,\n",
    "    'LEARNING_RATE':1e-4,\n",
    "    'BATCH_SIZE':256,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 및 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip open.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('df_aug.csv')\n",
    "df_copy=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "      <th>유형</th>\n",
       "      <th>극성</th>\n",
       "      <th>시제</th>\n",
       "      <th>확실성</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>비가 내리는 지역에서는 치고 곳이 지역에선 우박이 떨어지는 일부 있을 예정이다</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>비가 떨어지는 지역에서는 돌풍과 함께 천둥번개가 치고 일부 지역에선 우박이 내리는 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>비가 내리는 지역에서는 돌풍과 함께 천둥번개가 치고 일부 우박이 있을 곳이 떨어지는...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>비가 곳이 지역에서는 천둥번개가 치고 일부 우박이 떨어지는 내리는 예정이다</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>비가 내리는 곳이 돌풍과 치고 일부 지역에선 우박이 떨어지는 지역에서는 예정이다</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28119</th>\n",
       "      <td>또한 a씨가 자신이 근무한 편의점에서 1일 동안 최소 1만원 이상의 돈을 들여 상품...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28120</th>\n",
       "      <td>오유리 빗썸경제연구소 정책연구팀장은 국내 규제가 미국의 동향을 따를 가능성이 높은 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28121</th>\n",
       "      <td>보라네트워크는 카카오게임즈의 계열사다</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28122</th>\n",
       "      <td>컴투스는 최근 크리티카 글로벌의 a1a 블록체인 생태계 합류를 위해 참여자들이 직접...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28123</th>\n",
       "      <td>여기에 더불어민주당의 두 번째 고민이 담겨 있다</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28124 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      문장  유형  극성  시제  확실성\n",
       "0            비가 내리는 지역에서는 치고 곳이 지역에선 우박이 떨어지는 일부 있을 예정이다   2   0   1    0\n",
       "1      비가 떨어지는 지역에서는 돌풍과 함께 천둥번개가 치고 일부 지역에선 우박이 내리는 ...   2   0   1    0\n",
       "2      비가 내리는 지역에서는 돌풍과 함께 천둥번개가 치고 일부 우박이 있을 곳이 떨어지는...   2   0   1    0\n",
       "3              비가 곳이 지역에서는 천둥번개가 치고 일부 우박이 떨어지는 내리는 예정이다   2   0   1    0\n",
       "4           비가 내리는 곳이 돌풍과 치고 일부 지역에선 우박이 떨어지는 지역에서는 예정이다   2   0   1    0\n",
       "...                                                  ...  ..  ..  ..  ...\n",
       "28119  또한 a씨가 자신이 근무한 편의점에서 1일 동안 최소 1만원 이상의 돈을 들여 상품...   1   0   0    0\n",
       "28120  오유리 빗썸경제연구소 정책연구팀장은 국내 규제가 미국의 동향을 따를 가능성이 높은 ...   1   0   0    1\n",
       "28121                               보라네트워크는 카카오게임즈의 계열사다   1   0   2    1\n",
       "28122  컴투스는 최근 크리티카 글로벌의 a1a 블록체인 생태계 합류를 위해 참여자들이 직접...   1   0   0    1\n",
       "28123                         여기에 더불어민주당의 두 번째 고민이 담겨 있다   1   0   2    1\n",
       "\n",
       "[28124 rows x 5 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>문장</th>\n",
       "      <th>유형</th>\n",
       "      <th>극성</th>\n",
       "      <th>시제</th>\n",
       "      <th>확실성</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00000</td>\n",
       "      <td>0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00001</td>\n",
       "      <td>이어 ＂앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정＂이라며 ＂그 이전이...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00002</td>\n",
       "      <td>정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30%에서 37%까지...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>미래</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-미래-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00003</td>\n",
       "      <td>서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만, 하루 만에 ...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00004</td>\n",
       "      <td>익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다.</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16536</th>\n",
       "      <td>TRAIN_16536</td>\n",
       "      <td>＇신동덤＇은 ＇신비한 동물사전＇과 ＇해리 포터＇ 시리즈를 잇는 마법 어드벤처물로, ...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16537</th>\n",
       "      <td>TRAIN_16537</td>\n",
       "      <td>수족냉증은 어릴 때부터 심했으며 관절은 어디 한 곳이 아니고 목, 어깨, 팔꿈치, ...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16538</th>\n",
       "      <td>TRAIN_16538</td>\n",
       "      <td>김금희 소설가는 ＂계약서 조정이 그리 어려운가 작가를 격려한다면서 그런 문구 하나 ...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16539</th>\n",
       "      <td>TRAIN_16539</td>\n",
       "      <td>1만명이 넘는 방문자수를 기록한 이번 전시회는 총 77개 작품을 넥슨 사옥을 그대로...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>불확실</td>\n",
       "      <td>사실형-긍정-과거-불확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16540</th>\n",
       "      <td>TRAIN_16540</td>\n",
       "      <td>《목민심서》의 내용이다.</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16541 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID                                                 문장   유형  \\\n",
       "0      TRAIN_00000              0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.  사실형   \n",
       "1      TRAIN_00001  이어 ＂앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정＂이라며 ＂그 이전이...  사실형   \n",
       "2      TRAIN_00002  정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30%에서 37%까지...  사실형   \n",
       "3      TRAIN_00003  서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만, 하루 만에 ...  사실형   \n",
       "4      TRAIN_00004           익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다.  사실형   \n",
       "...            ...                                                ...  ...   \n",
       "16536  TRAIN_16536  ＇신동덤＇은 ＇신비한 동물사전＇과 ＇해리 포터＇ 시리즈를 잇는 마법 어드벤처물로, ...  사실형   \n",
       "16537  TRAIN_16537  수족냉증은 어릴 때부터 심했으며 관절은 어디 한 곳이 아니고 목, 어깨, 팔꿈치, ...  사실형   \n",
       "16538  TRAIN_16538  김금희 소설가는 ＂계약서 조정이 그리 어려운가 작가를 격려한다면서 그런 문구 하나 ...  사실형   \n",
       "16539  TRAIN_16539  1만명이 넘는 방문자수를 기록한 이번 전시회는 총 77개 작품을 넥슨 사옥을 그대로...  사실형   \n",
       "16540  TRAIN_16540                                      《목민심서》의 내용이다.  사실형   \n",
       "\n",
       "       극성  시제  확실성          label  \n",
       "0      긍정  현재   확실   사실형-긍정-현재-확실  \n",
       "1      긍정  과거   확실   사실형-긍정-과거-확실  \n",
       "2      긍정  미래   확실   사실형-긍정-미래-확실  \n",
       "3      긍정  과거   확실   사실형-긍정-과거-확실  \n",
       "4      긍정  현재   확실   사실형-긍정-현재-확실  \n",
       "...    ..  ..  ...            ...  \n",
       "16536  긍정  과거   확실   사실형-긍정-과거-확실  \n",
       "16537  긍정  과거   확실   사실형-긍정-과거-확실  \n",
       "16538  긍정  과거   확실   사실형-긍정-과거-확실  \n",
       "16539  긍정  과거  불확실  사실형-긍정-과거-불확실  \n",
       "16540  긍정  현재   확실   사실형-긍정-현재-확실  \n",
       "\n",
       "[16541 rows x 7 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val= train_test_split(df, test_size=0.2, random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>문장</th>\n",
       "      <th>유형</th>\n",
       "      <th>극성</th>\n",
       "      <th>시제</th>\n",
       "      <th>확실성</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11351</th>\n",
       "      <td>TRAIN_11372</td>\n",
       "      <td>지방 관리들이 세금을 가로채기 위해 중앙정부에 가능한 실제 인구수를 감추어 신고해 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10069</th>\n",
       "      <td>TRAIN_10087</td>\n",
       "      <td>중국 정부와 공산당 국민이 이심전심으로 일사불란하게 움직이며 이어가는 전근대적 규제다</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10902</th>\n",
       "      <td>TRAIN_10922</td>\n",
       "      <td>소득 격차가 줄어든 것이 저소득층이 일해 번 소득이 늘어서가 아니라 고소득층 소득 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14003</th>\n",
       "      <td>TRAIN_14032</td>\n",
       "      <td>1일부터 1일까지 열리는 서리산의 대왕의 경우 시즌1 에피소드1 얼음동굴편에 등장하...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7622</th>\n",
       "      <td>TRAIN_07635</td>\n",
       "      <td>삼성전자가 이번주에만 1주 연속 신저가를 1번 넘게 갈아치우며 가파른 하락세를 타자...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6819</th>\n",
       "      <td>TRAIN_06829</td>\n",
       "      <td>한국 추상화 거장 이우환이 1년 위작 파동 이후 처음으로 국내 개인전을 연다</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15829</th>\n",
       "      <td>TRAIN_15861</td>\n",
       "      <td>층수만 본래 1층에서 1층으로 증축됐을 뿐 1여년간 한 자리를 지켜왔다</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>TRAIN_08528</td>\n",
       "      <td>반려동물이 가장 많이 탑승한 노선은 제주였고 특히 부산제주 노선은 전체 운항 편수 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>TRAIN_00932</td>\n",
       "      <td>아이리시맨는 그 다음이었다</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>TRAIN_01987</td>\n",
       "      <td>기업들은 앞으로 리스크 분산에 더 많은 돈을 써야 한다</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13204 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID                                                 문장  유형  극성  \\\n",
       "11351  TRAIN_11372  지방 관리들이 세금을 가로채기 위해 중앙정부에 가능한 실제 인구수를 감추어 신고해 ...   1   0   \n",
       "10069  TRAIN_10087    중국 정부와 공산당 국민이 이심전심으로 일사불란하게 움직이며 이어가는 전근대적 규제다   1   0   \n",
       "10902  TRAIN_10922  소득 격차가 줄어든 것이 저소득층이 일해 번 소득이 늘어서가 아니라 고소득층 소득 ...   3   0   \n",
       "14003  TRAIN_14032  1일부터 1일까지 열리는 서리산의 대왕의 경우 시즌1 에피소드1 얼음동굴편에 등장하...   1   0   \n",
       "7622   TRAIN_07635  삼성전자가 이번주에만 1주 연속 신저가를 1번 넘게 갈아치우며 가파른 하락세를 타자...   1   0   \n",
       "...            ...                                                ...  ..  ..   \n",
       "6819   TRAIN_06829         한국 추상화 거장 이우환이 1년 위작 파동 이후 처음으로 국내 개인전을 연다   1   0   \n",
       "15829  TRAIN_15861            층수만 본래 1층에서 1층으로 증축됐을 뿐 1여년간 한 자리를 지켜왔다   1   0   \n",
       "8513   TRAIN_08528  반려동물이 가장 많이 탑승한 노선은 제주였고 특히 부산제주 노선은 전체 운항 편수 ...   1   0   \n",
       "931    TRAIN_00932                                     아이리시맨는 그 다음이었다   1   0   \n",
       "1984   TRAIN_01987                     기업들은 앞으로 리스크 분산에 더 많은 돈을 써야 한다   3   0   \n",
       "\n",
       "       시제  확실성  \n",
       "11351   0    1  \n",
       "10069   2    1  \n",
       "10902   2    1  \n",
       "14003   0    1  \n",
       "7622    2    1  \n",
       "...    ..  ...  \n",
       "6819    2    1  \n",
       "15829   0    1  \n",
       "8513    0    1  \n",
       "931     0    1  \n",
       "1984    1    1  \n",
       "\n",
       "[13204 rows x 6 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>문장</th>\n",
       "      <th>유형</th>\n",
       "      <th>극성</th>\n",
       "      <th>시제</th>\n",
       "      <th>확실성</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>TRAIN_04025</td>\n",
       "      <td>지난 1일 지효는 a앱 트와이스 채널에서 팬들과 채팅을 하던 중 관종 웅앵웅이라는 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>TRAIN_04372</td>\n",
       "      <td>1년 이 대회에서 토머스는 1홀 최소타 신기록으로 우승한 좋은 기억도 있다</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>TRAIN_00605</td>\n",
       "      <td>샤론 최는 한국 국적 보유자로 미국 대학에서 영화를 공부 중인 만큼 봉 감독이 말하...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>TRAIN_00771</td>\n",
       "      <td>개발원 관계자는 인터넷으로 보장 내용을 설계할 경우 사고 발생시 충분한 보상을 받을...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034</th>\n",
       "      <td>TRAIN_03038</td>\n",
       "      <td>또 불포화 지방은 과일과 채소에 있는 카로티노이드 흡수를 도와 암 발생률을 감소시킬...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>TRAIN_03913</td>\n",
       "      <td>실로 오랜만에 주어진 행복을 행여 놓칠세라 카메라에 담는 여행자들의 모습이 정겹다</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16079</th>\n",
       "      <td>TRAIN_16112</td>\n",
       "      <td>aa의 운용 주체인 공군은 1월 1일부터 오는 1일까지 한국형 전투기 aa 명칭 공...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>TRAIN_02571</td>\n",
       "      <td>각본상을 받은 뒤에는 시나리오를 쓴다는 게 사실 고독하고 외로운 작업이다 국가를 대...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11433</th>\n",
       "      <td>TRAIN_11455</td>\n",
       "      <td>해약 환급금 규모도 급격히 늘어나는 추세다</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15729</th>\n",
       "      <td>TRAIN_15760</td>\n",
       "      <td>인수합병 시장에 매물로 나온 보험사 중 최대어로 평가받는 푸르덴셜생명은 전문성을 갖...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3302 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID                                                 문장  유형  극성  \\\n",
       "4020   TRAIN_04025  지난 1일 지효는 a앱 트와이스 채널에서 팬들과 채팅을 하던 중 관종 웅앵웅이라는 ...   1   0   \n",
       "4366   TRAIN_04372          1년 이 대회에서 토머스는 1홀 최소타 신기록으로 우승한 좋은 기억도 있다   1   0   \n",
       "604    TRAIN_00605  샤론 최는 한국 국적 보유자로 미국 대학에서 영화를 공부 중인 만큼 봉 감독이 말하...   1   0   \n",
       "770    TRAIN_00771  개발원 관계자는 인터넷으로 보장 내용을 설계할 경우 사고 발생시 충분한 보상을 받을...   3   0   \n",
       "3034   TRAIN_03038  또 불포화 지방은 과일과 채소에 있는 카로티노이드 흡수를 도와 암 발생률을 감소시킬...   1   0   \n",
       "...            ...                                                ...  ..  ..   \n",
       "3908   TRAIN_03913      실로 오랜만에 주어진 행복을 행여 놓칠세라 카메라에 담는 여행자들의 모습이 정겹다   3   0   \n",
       "16079  TRAIN_16112  aa의 운용 주체인 공군은 1월 1일부터 오는 1일까지 한국형 전투기 aa 명칭 공...   1   1   \n",
       "2567   TRAIN_02571  각본상을 받은 뒤에는 시나리오를 쓴다는 게 사실 고독하고 외로운 작업이다 국가를 대...   1   0   \n",
       "11433  TRAIN_11455                            해약 환급금 규모도 급격히 늘어나는 추세다   1   0   \n",
       "15729  TRAIN_15760  인수합병 시장에 매물로 나온 보험사 중 최대어로 평가받는 푸르덴셜생명은 전문성을 갖...   1   0   \n",
       "\n",
       "       시제  확실성  \n",
       "4020    0    1  \n",
       "4366    0    1  \n",
       "604     2    1  \n",
       "770     0    1  \n",
       "3034    1    0  \n",
       "...    ..  ...  \n",
       "3908    2    1  \n",
       "16079   1    1  \n",
       "2567    0    1  \n",
       "11433   2    1  \n",
       "15729   2    1  \n",
       "\n",
       "[3302 rows x 6 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(r'C:\\Users\\WONJONGHYEON\\OneDrive\\바탕 화면\\cp2-competition\\test.csv')\n",
    "test_copy=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>문장</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>장욱진의 ＇가족＇은 허물 없는 가족애를, 처음 공개되는 정약용의 ＇정효자전＇과 ＇정...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>조지 W 부시, 버락 오바마 전 대통령도 전쟁 위험 때문에 버린 카드다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>지난해 1분기 128억원이었던 영업이익이 올해 1분기 505억원으로 급증했다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>수상 작가와 맺으려던 계약서 내용 가운데 일부가 ＇독소 조항＇으로 해석돼 수정을 요...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>결국 최근 KDB산업은행은 대규모 손실 위기에 닥친 에어부산에 140억원 금융지원을...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7085</th>\n",
       "      <td>TEST_7085</td>\n",
       "      <td>2020 세계국가편람 모바일 앱은 세계 216개국의 국가개황과 주요 경제지표, 사회...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>TEST_7086</td>\n",
       "      <td>탈세계화 징후들이 반갑지 않은 이유다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7087</th>\n",
       "      <td>TEST_7087</td>\n",
       "      <td>틱톡은 6월 ＇인터넷 안전의 달＇을 맞아 올바른 개인정보 보호 관리 방법, 앱 내 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>TEST_7088</td>\n",
       "      <td>만약 3개월 간 채굴자들의 투표를 거쳐 2/3 이상의 해시파워가 ＇채굴세＇ 도입에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7089</th>\n",
       "      <td>TEST_7089</td>\n",
       "      <td>아버지 홍언필이 인기척에 깨 그 광경을 지켜봤다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7090 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                                 문장\n",
       "0     TEST_0000  장욱진의 ＇가족＇은 허물 없는 가족애를, 처음 공개되는 정약용의 ＇정효자전＇과 ＇정...\n",
       "1     TEST_0001           조지 W 부시, 버락 오바마 전 대통령도 전쟁 위험 때문에 버린 카드다.\n",
       "2     TEST_0002        지난해 1분기 128억원이었던 영업이익이 올해 1분기 505억원으로 급증했다.\n",
       "3     TEST_0003  수상 작가와 맺으려던 계약서 내용 가운데 일부가 ＇독소 조항＇으로 해석돼 수정을 요...\n",
       "4     TEST_0004  결국 최근 KDB산업은행은 대규모 손실 위기에 닥친 에어부산에 140억원 금융지원을...\n",
       "...         ...                                                ...\n",
       "7085  TEST_7085  2020 세계국가편람 모바일 앱은 세계 216개국의 국가개황과 주요 경제지표, 사회...\n",
       "7086  TEST_7086                              탈세계화 징후들이 반갑지 않은 이유다.\n",
       "7087  TEST_7087  틱톡은 6월 ＇인터넷 안전의 달＇을 맞아 올바른 개인정보 보호 관리 방법, 앱 내 ...\n",
       "7088  TEST_7088  만약 3개월 간 채굴자들의 투표를 거쳐 2/3 이상의 해시파워가 ＇채굴세＇ 도입에 ...\n",
       "7089  TEST_7089                        아버지 홍언필이 인기척에 깨 그 광경을 지켜봤다.\n",
       "\n",
       "[7090 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 벡터화 및 레이블링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Label Encoding (유형, 극성, 시제, 확실성)\n",
    "type_le = preprocessing.LabelEncoder()\n",
    "train[\"유형\"] = type_le.fit_transform(train[\"유형\"].values)\n",
    "val[\"유형\"] = type_le.transform(val[\"유형\"].values)\n",
    "\n",
    "polarity_le = preprocessing.LabelEncoder()\n",
    "train[\"극성\"] = polarity_le.fit_transform(train[\"극성\"].values)\n",
    "val[\"극성\"] = polarity_le.transform(val[\"극성\"].values)\n",
    "\n",
    "tense_le = preprocessing.LabelEncoder()\n",
    "train[\"시제\"] = tense_le.fit_transform(train[\"시제\"].values)\n",
    "val[\"시제\"] = tense_le.transform(val[\"시제\"].values)\n",
    "\n",
    "certainty_le = preprocessing.LabelEncoder()\n",
    "train[\"확실성\"] = certainty_le.fit_transform(train[\"확실성\"].values)\n",
    "val[\"확실성\"] = certainty_le.transform(val[\"확실성\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13204, 8889) (3302, 8889) (7090, 8889)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df = 4, analyzer = 'word', ngram_range=(1, 2))\n",
    "vectorizer.fit(np.array(train[\"문장\"]))\n",
    "\n",
    "train_vec = vectorizer.transform(train[\"문장\"])\n",
    "val_vec = vectorizer.transform(val[\"문장\"])\n",
    "test_vec = vectorizer.transform(test[\"문장\"])\n",
    "\n",
    "print(train_vec.shape, val_vec.shape, test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_type = train[\"유형\"].values # sentence type\n",
    "train_polarity = train[\"극성\"].values # sentence polarity\n",
    "train_tense = train[\"시제\"].values # sentence tense\n",
    "train_certainty = train[\"확실성\"].values # sentence certainty\n",
    "\n",
    "train_labels = {\n",
    "    'type' : train_type,\n",
    "    'polarity' : train_polarity,\n",
    "    'tense' : train_tense,\n",
    "    'certainty' : train_certainty\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_type = val[\"유형\"].values # sentence type\n",
    "val_polarity = val[\"극성\"].values # sentence polarity\n",
    "val_tense = val[\"시제\"].values # sentence tense\n",
    "val_certainty = val[\"확실성\"].values # sentence certainty\n",
    "\n",
    "val_labels = {\n",
    "    'type' : val_type,\n",
    "    'polarity' : val_polarity,\n",
    "    'tense' : val_tense,\n",
    "    'certainty' : val_certainty\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, st_vec, st_labels):\n",
    "        self.st_vec = st_vec\n",
    "        self.st_labels = st_labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        st_vector = torch.FloatTensor(self.st_vec[index].toarray()).squeeze(0)\n",
    "        if self.st_labels is not None:\n",
    "            st_type = self.st_labels['type'][index]\n",
    "            st_polarity = self.st_labels['polarity'][index]\n",
    "            st_tense = self.st_labels['tense'][index]\n",
    "            st_certainty = self.st_labels['certainty'][index]\n",
    "            return st_vector, st_type, st_polarity, st_tense, st_certainty\n",
    "        else:\n",
    "            return st_vector\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.st_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_vec, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val_vec, val_labels)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0.,  ..., 0., 0., 0.]), 1, 0, 2, 1)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6195)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(train_dataset[132][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 베이스모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, input_dim=8889):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.feature_extract = nn.Sequential(\n",
    "            nn.Linear(in_features=input_dim, out_features=1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.type_classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(in_features=512, out_features=4),\n",
    "        )\n",
    "        self.polarity_classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(in_features=512, out_features=3),\n",
    "        )\n",
    "        self.tense_classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(in_features=512, out_features=3),\n",
    "        )\n",
    "        self.certainty_classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(in_features=512, out_features=2),\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extract(x)\n",
    "        # 문장 유형, 극성, 시제, 확실성을 각각 분류\n",
    "        type_output = self.type_classifier(x)\n",
    "        polarity_output = self.polarity_classifier(x)\n",
    "        tense_output = self.tense_classifier(x)\n",
    "        certainty_output = self.certainty_classifier(x)\n",
    "        return type_output, polarity_output, tense_output, certainty_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = {\n",
    "        'type' : nn.CrossEntropyLoss().to(device),\n",
    "        'polarity' : nn.CrossEntropyLoss().to(device),\n",
    "        'tense' : nn.CrossEntropyLoss().to(device),\n",
    "        'certainty' : nn.CrossEntropyLoss().to(device)\n",
    "    }\n",
    "    \n",
    "    best_loss = 999999\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for sentence, type_label, polarity_label, tense_label, certainty_label in tqdm(iter(train_loader)):\n",
    "            sentence = sentence.to(device)\n",
    "            type_label = type_label.to(device)\n",
    "            polarity_label = polarity_label.to(device)\n",
    "            tense_label = tense_label.to(device)\n",
    "            certainty_label = certainty_label.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            type_logit, polarity_logit, tense_logit, certainty_logit = model(sentence)\n",
    "            \n",
    "            loss = 0.25 * criterion['type'](type_logit, type_label) + \\\n",
    "                    0.25 * criterion['polarity'](polarity_logit, polarity_label) + \\\n",
    "                    0.25 * criterion['tense'](tense_logit, tense_label) + \\\n",
    "                    0.25 * criterion['certainty'](certainty_logit, certainty_label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        val_loss, val_type_f1, val_polarity_f1, val_tense_f1, val_certainty_f1 = validation(model, val_loader, criterion, device)\n",
    "        print(f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss):.5f}] Val Loss : [{val_loss:.5f}] 유형 F1 : [{val_type_f1:.5f}] 극성 F1 : [{val_polarity_f1:.5f}] 시제 F1 : [{val_tense_f1:.5f}] 확실성 F1 : [{val_certainty_f1:.5f}]')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "        if best_loss > val_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model\n",
    "            \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    \n",
    "    type_preds, polarity_preds, tense_preds, certainty_preds = [], [], [], []\n",
    "    type_labels, polarity_labels, tense_labels, certainty_labels = [], [], [], []\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sentence, type_label, polarity_label, tense_label, certainty_label in tqdm(iter(val_loader)):\n",
    "            sentence = sentence.to(device)\n",
    "            type_label = type_label.to(device)\n",
    "            polarity_label = polarity_label.to(device)\n",
    "            tense_label = tense_label.to(device)\n",
    "            certainty_label = certainty_label.to(device)\n",
    "            \n",
    "            type_logit, polarity_logit, tense_logit, certainty_logit = model(sentence)\n",
    "            \n",
    "            loss = 0.25 * criterion['type'](type_logit, type_label) + \\\n",
    "                    0.25 * criterion['polarity'](polarity_logit, polarity_label) + \\\n",
    "                    0.25 * criterion['tense'](tense_logit, tense_label) + \\\n",
    "                    0.25 * criterion['certainty'](certainty_logit, certainty_label)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "            type_preds += type_logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            type_labels += type_label.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            polarity_preds += polarity_logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            polarity_labels += polarity_label.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            tense_preds += tense_logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            tense_labels += tense_label.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            certainty_preds += certainty_logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            certainty_labels += certainty_label.detach().cpu().numpy().tolist()\n",
    "    \n",
    "    type_f1 = f1_score(type_labels, type_preds, average='weighted')\n",
    "    polarity_f1 = f1_score(polarity_labels, polarity_preds, average='weighted')\n",
    "    tense_f1 = f1_score(tense_labels, tense_preds, average='weighted')\n",
    "    certainty_f1 = f1_score(certainty_labels, certainty_preds, average='weighted')\n",
    "    \n",
    "    return np.mean(val_loss), type_f1, polarity_f1, tense_f1, certainty_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:28<00:00,  1.86it/s]\n",
      "100%|██████████| 13/13 [00:02<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.73990] Val Loss : [0.56353] 유형 F1 : [0.73694] 극성 F1 : [0.93820] 시제 F1 : [0.46060] 확실성 F1 : [0.88130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:25<00:00,  2.05it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.30053] Val Loss : [0.42710] 유형 F1 : [0.77207] 극성 F1 : [0.95047] 시제 F1 : [0.71788] 확실성 F1 : [0.88869]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:36<00:00,  1.41it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.15445] Val Loss : [0.40180] 유형 F1 : [0.78617] 극성 F1 : [0.95520] 시제 F1 : [0.72724] 확실성 F1 : [0.89450]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:23<00:00,  2.20it/s]\n",
      "100%|██████████| 13/13 [00:02<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4] Train Loss : [0.08874] Val Loss : [0.40582] 유형 F1 : [0.78788] 극성 F1 : [0.95715] 시제 F1 : [0.72807] 확실성 F1 : [0.89573]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:25<00:00,  2.01it/s]\n",
      "100%|██████████| 13/13 [00:02<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5] Train Loss : [0.05836] Val Loss : [0.41261] 유형 F1 : [0.79129] 극성 F1 : [0.95911] 시제 F1 : [0.72314] 확실성 F1 : [0.89572]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 13/52 [00:07<00:22,  1.71it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[175], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(params \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mparameters(), lr \u001b[39m=\u001b[39m CFG[\u001b[39m\"\u001b[39m\u001b[39mLEARNING_RATE\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m      4\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mReduceLROnPlateau(optimizer, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,threshold_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mabs\u001b[39m\u001b[39m'\u001b[39m,min_lr\u001b[39m=\u001b[39m\u001b[39m1e-8\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 6\u001b[0m train(model, optimizer, train_loader, val_loader, scheduler, device)\n",
      "Cell \u001b[1;32mIn[173], line 24\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, train_loader, val_loader, scheduler, device)\u001b[0m\n\u001b[0;32m     21\u001b[0m tense_label \u001b[39m=\u001b[39m tense_label\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     22\u001b[0m certainty_label \u001b[39m=\u001b[39m certainty_label\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 24\u001b[0m optimizer\u001b[39m.\u001b[39;49mzero_grad()\n\u001b[0;32m     26\u001b[0m type_logit, polarity_logit, tense_logit, certainty_logit \u001b[39m=\u001b[39m model(sentence)\n\u001b[0;32m     28\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0.25\u001b[39m \u001b[39m*\u001b[39m criterion[\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m](type_logit, type_label) \u001b[39m+\u001b[39m \\\n\u001b[0;32m     29\u001b[0m         \u001b[39m0.25\u001b[39m \u001b[39m*\u001b[39m criterion[\u001b[39m'\u001b[39m\u001b[39mpolarity\u001b[39m\u001b[39m'\u001b[39m](polarity_logit, polarity_label) \u001b[39m+\u001b[39m \\\n\u001b[0;32m     30\u001b[0m         \u001b[39m0.25\u001b[39m \u001b[39m*\u001b[39m criterion[\u001b[39m'\u001b[39m\u001b[39mtense\u001b[39m\u001b[39m'\u001b[39m](tense_logit, tense_label) \u001b[39m+\u001b[39m \\\n\u001b[0;32m     31\u001b[0m         \u001b[39m0.25\u001b[39m \u001b[39m*\u001b[39m criterion[\u001b[39m'\u001b[39m\u001b[39mcertainty\u001b[39m\u001b[39m'\u001b[39m](certainty_logit, certainty_label)\n",
      "File \u001b[1;32mc:\\Users\\WONJONGHYEON\\anaconda3\\envs\\CP2\\lib\\site-packages\\torch\\optim\\optimizer.py:461\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39mgrad \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[39mif\u001b[39;00m set_to_none:\n\u001b[1;32m--> 461\u001b[0m         p\u001b[39m.\u001b[39;49mgrad \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    463\u001b[0m         \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mgrad_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = BaseModel()\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2,threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "\n",
    "train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModel(\n",
       "  (feature_extract): Sequential(\n",
       "    (0): Linear(in_features=8889, out_features=1024, bias=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (type_classifier): Sequential(\n",
       "    (0): Dropout(p=0.3, inplace=False)\n",
       "    (1): Linear(in_features=512, out_features=4, bias=True)\n",
       "  )\n",
       "  (polarity_classifier): Sequential(\n",
       "    (0): Dropout(p=0.3, inplace=False)\n",
       "    (1): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       "  (tense_classifier): Sequential(\n",
       "    (0): Dropout(p=0.3, inplace=False)\n",
       "    (1): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       "  (certainty_classifier): Sequential(\n",
       "    (0): Dropout(p=0.3, inplace=False)\n",
       "    (1): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_vec, None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    type_preds, polarity_preds, tense_preds, certainty_preds = [], [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sentence in tqdm(test_loader):\n",
    "            sentence = sentence.to(device)\n",
    "            \n",
    "            type_logit, polarity_logit, tense_logit, certainty_logit = model(sentence)\n",
    "            \n",
    "            type_preds += type_logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            polarity_preds += polarity_logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            tense_preds += tense_logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            certainty_preds += certainty_logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            \n",
    "    return type_preds, polarity_preds, tense_preds, certainty_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:05<00:00,  5.51it/s]\n"
     ]
    }
   ],
   "source": [
    "type_preds, polarity_preds, tense_preds, certainty_preds = inference(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1691114245416079"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(type_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_preds = type_le.inverse_transform(type_preds)\n",
    "polarity_preds = polarity_le.inverse_transform(polarity_preds)\n",
    "tense_preds = tense_le.inverse_transform(tense_preds)\n",
    "certainty_preds = certainty_le.inverse_transform(certainty_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for type_pred, polarity_pred, tense_pred, certainty_pred in zip(type_preds, polarity_preds, tense_preds, certainty_preds):\n",
    "    predictions.append(type_pred+'-'+polarity_pred+'-'+tense_pred+'-'+certainty_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(r'C:\\Users\\WONJONGHYEON\\OneDrive\\바탕 화면\\cp2-competition\\sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submit['label'] = submit['유형'] + '-' + submit['극성'] + '-' + submit['시제'] + '-' + submit['확실성']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7085</th>\n",
       "      <td>TEST_7085</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>TEST_7086</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7087</th>\n",
       "      <td>TEST_7087</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>TEST_7088</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7089</th>\n",
       "      <td>TEST_7089</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7090 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID         label\n",
       "0     TEST_0000  사실형-긍정-과거-확실\n",
       "1     TEST_0001  사실형-긍정-현재-확실\n",
       "2     TEST_0002  사실형-긍정-과거-확실\n",
       "3     TEST_0003  사실형-긍정-과거-확실\n",
       "4     TEST_0004  사실형-긍정-과거-확실\n",
       "...         ...           ...\n",
       "7085  TEST_7085  사실형-긍정-현재-확실\n",
       "7086  TEST_7086  추론형-긍정-현재-확실\n",
       "7087  TEST_7087  사실형-긍정-현재-확실\n",
       "7088  TEST_7088  사실형-긍정-현재-확실\n",
       "7089  TEST_7089  사실형-긍정-과거-확실\n",
       "\n",
       "[7090 rows x 2 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submit_bs2.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e5bac9dc713ed5e7b0e2455bebe074a3a25a24fa4d9650e1e42f8c8e58e6ce4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
